#!/usr/bin/env python3
"""
Script completo de procesamiento de archivos JSON para Ciencia de Datos
Demuestra JSON estÃ¡ndar, JSON Lines, JSON Schema, y conversiÃ³n a otros formatos
"""

import json
import jsonschema
from jsonschema import validate, ValidationError
from typing import Dict, List, Any
import pandas as pd
from collections import defaultdict
import os


def cargar_json(archivo: str) -> Dict:
    """
    Carga un archivo JSON
    
    Args:
        archivo: Ruta al archivo JSON
        
    Returns:
        Diccionario con datos JSON
    """
    with open(archivo, 'r', encoding='utf-8') as f:
        return json.load(f)


def cargar_jsonl(archivo: str) -> List[Dict]:
    """
    Carga un archivo JSON Lines (cada lÃ­nea es un JSON)
    
    Args:
        archivo: Ruta al archivo JSONL
        
    Returns:
        Lista de diccionarios
    """
    datos = []
    with open(archivo, 'r', encoding='utf-8') as f:
        for linea in f:
            if linea.strip():  # Ignorar lÃ­neas vacÃ­as
                datos.append(json.loads(linea))
    return datos


def analizar_estructura_json(datos: Any, prefijo: str = "", max_profundidad: int = 5):
    """
    Analiza recursivamente la estructura de un JSON
    
    Args:
        datos: Datos JSON a analizar
        prefijo: Prefijo para el path actual
        max_profundidad: Profundidad mÃ¡xima de anÃ¡lisis
    """
    if max_profundidad == 0:
        print(f"{prefijo}: [profundidad mÃ¡xima alcanzada]")
        return
    
    if isinstance(datos, dict):
        for clave, valor in datos.items():
            nuevo_prefijo = f"{prefijo}.{clave}" if prefijo else clave
            tipo = type(valor).__name__
            
            if isinstance(valor, (dict, list)):
                tamaÃ±o = len(valor)
                print(f"{nuevo_prefijo}: {tipo} (tamaÃ±o={tamaÃ±o})")
                analizar_estructura_json(valor, nuevo_prefijo, max_profundidad - 1)
            else:
                print(f"{nuevo_prefijo}: {tipo} = {repr(valor)[:50]}")
    
    elif isinstance(datos, list):
        if len(datos) > 0:
            print(f"{prefijo}[0]: {type(datos[0]).__name__}")
            if len(datos) > 1:
                print(f"{prefijo}[1..{len(datos)-1}]: ... ({len(datos)-1} elementos mÃ¡s)")
            analizar_estructura_json(datos[0], f"{prefijo}[0]", max_profundidad - 1)


def validar_con_schema(datos_json: Dict, schema_json: Dict) -> bool:
    """
    Valida datos JSON contra un JSON Schema
    
    Args:
        datos_json: Datos a validar
        schema_json: Schema JSON
        
    Returns:
        True si es vÃ¡lido, False en caso contrario
    """
    try:
        validate(instance=datos_json, schema=schema_json)
        print("âœ“ JSON es vÃ¡lido segÃºn el schema")
        return True
    except ValidationError as e:
        print(f"âœ— JSON no es vÃ¡lido:")
        print(f"  Error: {e.message}")
        print(f"  Path: {' -> '.join(str(p) for p in e.path)}")
        print(f"  Schema path: {' -> '.join(str(p) for p in e.schema_path)}")
        return False


def extraer_metricas_experimentos(datos: Dict) -> pd.DataFrame:
    """
    Extrae mÃ©tricas de experimentos a DataFrame
    
    Args:
        datos: Datos JSON con experimentos
        
    Returns:
        DataFrame con mÃ©tricas
    """
    experimentos = datos['investigacion']['experimentos']
    
    filas = []
    for exp in experimentos:
        fila = {
            'id': exp['id'],
            'fecha': exp['fecha'],
            'modelo': exp['modelo']['nombre'],
            'arquitectura': exp['modelo']['arquitectura'],
            'parametros': exp['modelo']['parametros'],
            'batch_size': exp['hiperparametros']['batch_size'],
            'learning_rate': exp['hiperparametros']['learning_rate'],
            'epochs': exp['hiperparametros']['epochs'],
            'accuracy': exp['resultados']['accuracy'],
            'precision': exp['resultados']['precision'],
            'recall': exp['resultados']['recall'],
            'f1_score': exp['resultados']['f1_score'],
            'tiempo_entrenamiento_seg': exp['resultados']['tiempo_entrenamiento_seg'],
            'tiempo_inferencia_ms': exp['resultados']['tiempo_inferencia_ms']
        }
        filas.append(fila)
    
    return pd.DataFrame(filas)


def analizar_grafo_json(datos: Dict):
    """
    Analiza estadÃ­sticas de un grafo en formato JSON
    
    Args:
        datos: Datos del grafo en JSON
    """
    grafo = datos['grafo_conocimiento']
    
    print(f"\n{'='*70}")
    print(f"ANÃLISIS DEL GRAFO: {grafo['metadata']['nombre']}")
    print('='*70)
    
    # EstadÃ­sticas generales
    meta = grafo['metadata']
    stats = meta['estadisticas']
    print(f"\nğŸ“Š EstadÃ­sticas generales:")
    print(f"   â€¢ Nodos: {stats['num_nodos']}")
    print(f"   â€¢ Aristas: {stats['num_aristas']}")
    print(f"   â€¢ Densidad: {stats['densidad']:.4f}")
    print(f"   â€¢ DiÃ¡metro: {stats['diametro']}")
    
    # AnÃ¡lisis de nodos por tipo
    nodos_por_tipo = defaultdict(int)
    for nodo in grafo['nodos']:
        nodos_por_tipo[nodo['tipo']] += 1
    
    print(f"\nğŸ”µ Nodos por tipo:")
    for tipo, count in nodos_por_tipo.items():
        print(f"   â€¢ {tipo}: {count}")
    
    # AnÃ¡lisis de aristas por tipo
    aristas_por_tipo = defaultdict(int)
    for arista in grafo['aristas']:
        aristas_por_tipo[arista['tipo']] += 1
    
    print(f"\nğŸ”— Aristas por tipo:")
    for tipo, count in aristas_por_tipo.items():
        print(f"   â€¢ {tipo}: {count}")
    
    # Investigadores con mÃ¡s colaboraciones
    colaboraciones = defaultdict(list)
    for arista in grafo['aristas']:
        if arista['tipo'] == 'COLABORA_CON':
            fuente = arista['fuente']
            destino = arista['destino']
            fuerza = arista['propiedades']['fuerza_colaboracion']
            colaboraciones[fuente].append((destino, fuerza))
            colaboraciones[destino].append((fuente, fuerza))
    
    print(f"\nğŸ‘¥ Top investigadores por nÃºmero de colaboraciones:")
    top_colaboradores = sorted(
        colaboraciones.items(),
        key=lambda x: len(x[1]),
        reverse=True
    )[:3]
    
    for inv_id, colabs in top_colaboradores:
        # Buscar nombre del investigador
        nombre = next(
            (n['propiedades']['nombre'] for n in grafo['nodos'] if n['id'] == inv_id),
            inv_id
        )
        print(f"   â€¢ {nombre}: {len(colabs)} colaboraciones")


def json_vs_jsonl_demo():
    """
    Demuestra las diferencias entre JSON y JSON Lines
    """
    print(f"\n{'='*70}")
    print("JSON vs JSON LINES (JSONL)")
    print('='*70)
    
    # JSON estÃ¡ndar
    print("\nğŸ“„ JSON ESTÃNDAR:")
    print("   â€¢ Un Ãºnico objeto/array que contiene todos los datos")
    print("   â€¢ Debe cargarse completo en memoria")
    print("   â€¢ No se puede procesar lÃ­nea por lÃ­nea")
    print("   â€¢ Formato: { \"datos\": [...] }")
    
    # JSON Lines
    print("\nğŸ“„ JSON LINES (JSONL):")
    print("   â€¢ Cada lÃ­nea es un JSON vÃ¡lido independiente")
    print("   â€¢ Puede procesarse en streaming")
    print("   â€¢ Ideal para logs y datos de sensores")
    print("   â€¢ Formato: cada lÃ­nea es un JSON")
    
    # Cargar y mostrar JSONL
    datos_jsonl = cargar_jsonl('sensores_streaming.jsonl')
    print(f"\nâœ“ Cargadas {len(datos_jsonl)} lÃ­neas de sensores_streaming.jsonl")
    print("\nPrimeras 3 lÃ­neas:")
    for i, dato in enumerate(datos_jsonl[:3], 1):
        print(f"   {i}. {dato}")
    
    # Convertir JSONL a DataFrame
    df = pd.DataFrame(datos_jsonl)
    print(f"\nğŸ“Š Convertido a DataFrame: {df.shape[0]} filas Ã— {df.shape[1]} columnas")
    print(df.head())
    
    # EstadÃ­sticas por sensor
    print(f"\nğŸ“ˆ EstadÃ­sticas por sensor:")
    stats = df.groupby('sensor_id').agg({
        'temperatura': ['mean', 'std', 'min', 'max'],
        'humedad': ['mean', 'std']
    }).round(2)
    print(stats)


def json_nested_to_flat():
    """
    Demuestra cÃ³mo aplanar JSON anidado
    """
    print(f"\n{'='*70}")
    print("APLANAMIENTO DE JSON ANIDADO")
    print('='*70)
    
    datos = cargar_json('investigacion_nlp.json')
    
    # Extraer informaciÃ³n anidada
    inv = datos['investigacion']['investigador_principal']
    
    datos_planos = {
        'titulo': datos['investigacion']['titulo'],
        'investigador_nombre': inv['nombre'],
        'investigador_email': inv['email'],
        'institucion': inv['afiliacion']['institucion'],
        'departamento': inv['afiliacion']['departamento'],
        'pais': inv['afiliacion']['pais'],
        'num_tweets': datos['investigacion']['dataset']['tamaÃ±o']['tweets'],
        'tamano_mb': datos['investigacion']['dataset']['tamaÃ±o']['tamano_mb'],
        'mejor_modelo': datos['investigacion']['conclusiones']['mejor_modelo'],
        'mejor_accuracy': max(
            exp['resultados']['accuracy'] 
            for exp in datos['investigacion']['experimentos']
        )
    }
    
    print("\nJSON anidado original:")
    print(json.dumps(
        {k: datos['investigacion'][k] for k in ['titulo', 'investigador_principal']},
        indent=2,
        ensure_ascii=False
    )[:300] + "...")
    
    print("\nâ¡ï¸  JSON plano resultante:")
    print(json.dumps(datos_planos, indent=2, ensure_ascii=False))
    
    # Usar pandas para aplanar
    df_flat = pd.json_normalize(datos['investigacion'])
    print(f"\nâœ“ Aplanado con pandas.json_normalize:")
    print(f"  Columnas: {len(df_flat.columns)}")
    print(f"  Muestra de columnas: {list(df_flat.columns)[:5]}")


def comparacion_formatos():
    """
    Compara JSON con XML y CSV
    """
    print(f"\n{'='*70}")
    print("COMPARACIÃ“N: JSON vs XML vs CSV")
    print('='*70)
    
    comparacion = """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Aspecto     â”‚  JSON   â”‚   XML    â”‚    CSV    â”‚   Parquet   â”‚  Pickle  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Legibilidad  â”‚   â­â­â­â­   â”‚  â­â­â­    â”‚   â­â­â­â­â­   â”‚     â­       â”‚    â­     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TamaÃ±o       â”‚  Medio  â”‚  Grande  â”‚  PequeÃ±o  â”‚  Muy peq.   â”‚  Medio   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Parsing      â”‚  RÃ¡pido â”‚  Lento   â”‚  RÃ¡pido   â”‚  Muy rÃ¡pido â”‚ RÃ¡pido   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ AnidaciÃ³n    â”‚    âœ“    â”‚    âœ“     â”‚     âœ—     â”‚      âœ“      â”‚    âœ“     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tipos datos  â”‚ BÃ¡sicos â”‚ BÃ¡sicos  â”‚ Solo str  â”‚  Preserva   â”‚Preserva  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Streaming    â”‚ Limitadoâ”‚ Limitado â”‚     âœ“     â”‚      âœ“      â”‚    âœ—     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Schema       â”‚   âœ“ *   â”‚    âœ“     â”‚     âœ—     â”‚      âœ“      â”‚    âœ—     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Ecosistema   â”‚   Web   â”‚Enterpriseâ”‚ Universal â”‚  Big Data   â”‚  Python  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

* JSON Schema (estÃ¡ndar separado)

ğŸ¯ CUÃNDO USAR JSON:
  âœ“ APIs REST / GraphQL
  âœ“ ConfiguraciÃ³n de aplicaciones
  âœ“ Datos jerÃ¡rquicos (grafos, Ã¡rboles)
  âœ“ Intercambio web (JavaScript nativo)
  âœ“ NoSQL databases (MongoDB, CouchDB)

ğŸ¯ CUÃNDO USAR JSON LINES:
  âœ“ Logs de aplicaciones
  âœ“ Streaming de datos (IoT, eventos)
  âœ“ Datasets grandes que no caben en memoria
  âœ“ Procesamiento incremental
  âœ“ Machine Learning training data

âš ï¸  LIMITACIONES DE JSON:
  âœ— No soporta fechas nativas (usar ISO 8601 strings)
  âœ— No distingue int vs float (todo es "number")
  âœ— No soporta comentarios (usar "_comment" keys)
  âœ— No soporta referencias/punteros
  âœ— Archivos muy grandes son difÃ­ciles de editar
"""
    print(comparacion)


if __name__ == "__main__":
    print("="*70)
    print("EJEMPLOS PRÃCTICOS: PROCESAMIENTO DE JSON")
    print("="*70)
    
    # 1. Analizar estructura
    print("\n1. ANÃLISIS DE ESTRUCTURA JSON")
    print("-" * 70)
    datos_inv = cargar_json('investigacion_nlp.json')
    analizar_estructura_json(datos_inv, max_profundidad=3)
    
    # 2. Extraer mÃ©tricas
    print("\n2. EXTRACCIÃ“N DE MÃ‰TRICAS A DATAFRAME")
    print("-" * 70)
    df_metricas = extraer_metricas_experimentos(datos_inv)
    print(df_metricas.to_string(index=False))
    
    # 3. Analizar grafo
    datos_grafo = cargar_json('grafo_conocimiento.json')
    analizar_grafo_json(datos_grafo)
    
    # 4. JSON vs JSON Lines
    json_vs_jsonl_demo()
    
    # 5. Aplanamiento
    json_nested_to_flat()
    
    # 6. ValidaciÃ³n con schema
    print(f"\n{'='*70}")
    print("VALIDACIÃ“N CON JSON SCHEMA")
    print('='*70)
    
    schema = cargar_json('schema_experimento.json')
    
    # Ejemplo vÃ¡lido
    experimento_valido = {
        "id": "EXP-001",
        "fecha": "2025-11-19",
        "modelo": {
            "nombre": "BERT",
            "tipo": "clasificacion"
        },
        "dataset": {
            "nombre": "IMDB",
            "tamaÃ±o": {
                "train": 25000,
                "test": 25000
            }
        },
        "resultados": {
            "accuracy": 0.89
        }
    }
    
    print("\nâœ… Validando experimento vÃ¡lido:")
    validar_con_schema(experimento_valido, schema)
    
    # Ejemplo invÃ¡lido
    experimento_invalido = {
        "id": "EXP001",  # Formato incorrecto (falta guiÃ³n)
        "fecha": "2025-11-19",
        "modelo": {
            "nombre": "BERT",
            "tipo": "clasificacion"
        },
        "dataset": {
            "nombre": "IMDB",
            "tamaÃ±o": {
                "train": -100  # NÃºmero negativo (invÃ¡lido)
            }
        },
        "resultados": {
            "accuracy": 1.5  # Mayor que 1 (invÃ¡lido)
        }
    }
    
    print("\nâŒ Validando experimento invÃ¡lido:")
    validar_con_schema(experimento_invalido, schema)
    
    # 7. ComparaciÃ³n de formatos
    comparacion_formatos()
    
    print("\n" + "="*70)
    print("âœ“ Procesamiento completado")
    print("="*70)
